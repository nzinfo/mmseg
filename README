Coreseek MMSeg Tokenizer
================================

使用 MMSeg 进行中文切分，支持词组模式和全切分；
包括两个词库，基础词库和短语词库。
其中短语词库可以预先定义切分方案，如果没有给定切分方案，则使用基础词库进行切分；
对于词条可以设置属性



Build On Mac with brew
===============================
cmake .. -DPYTHON_LIBRARY=/usr/local/Cellar/python/2.7.6/Frameworks/Python.framework/Versions/2.7/lib/libpython2.7.dylib


Design
================================
1 使用Python 接口处理 字符类型 | 转小写(异体字)
2 每个词库有唯一的 最长255 个字长的名字, 系统不保证名字的唯一性,参考 JAVA 的包管理;
3 LUA 脚本通过注册回调的方式与分词系统发生交互
    - 注册在字上, 当出现了这一个字,则
    - 注册在Token上, 当出现了这个 Token
    - 注册在Token类型上, 主要是数字 ,则 ; 部分词条拥有固定的词类型, 1 char
    - 注册在词库上, 当出现了这个词库中的词, 主要用于专有词典|查询解析
    - LUA脚本可以
        1 修改分词结果
        2 修改标注结果
        3 修改自定义的 annote, 脚本修改这些内容时,应给定自己的特殊 tag, 如果不指定 tag, 这修改系统默认的
          ( 比如, 用于识别 文中出现的 人名 | 时间 | 剧集 , 格式为 [大类型=pos|ner|annote] [类型, value] )
    - LUA 脚本可以查看当前句子的上下文窗口, 前后 100 字
      可以查询系统已经标明的识别出的未登录词 (用于人名)

    - 在新增未登录词时, LUA 也能被回调, 用于根据规则, 处理人的称呼| 简写;

4 系统可以加载多个词库, 词库在运行时可以合并到唯一的一个 dart 上,用于加速查找
5 系统最多可以加载 32 个词库 (最多64, 不能再多了)
6 词库加载是,应该增加 options 参数,用于控制词库加载时的具体行为
7 需要引入 cpp 的 log 库
8 需要提供脚本, 构造词库, 解析Sphinx 的字符映射文件
